{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd684e40-648a-4985-8ffe-9514db7e7174",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/daniel/anaconda3/lib/python3.12/site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in /home/daniel/anaconda3/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/daniel/anaconda3/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/daniel/anaconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/daniel/anaconda3/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/daniel/anaconda3/lib/python3.12/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /home/daniel/anaconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/daniel/anaconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /home/daniel/anaconda3/lib/python3.12/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from datasets) (0.27.0)\n",
      "Requirement already satisfied: packaging in /home/daniel/anaconda3/lib/python3.12/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/daniel/anaconda3/lib/python3.12/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/daniel/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/daniel/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/daniel/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/daniel/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/daniel/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/daniel/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/daniel/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniel/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/daniel/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/daniel/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/daniel/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/daniel/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32d5e3a6-d340-4071-8056-1d579f5e2c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39cd93f936b46e8b6fe4d4a777f22a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/917 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Columns: ['blob_id', 'directory_id', 'path', 'content_id', 'detected_licenses', 'license_type', 'repo_name', 'snapshot_id', 'revision_id', 'branch_name', 'visit_date', 'revision_date', 'committer_date', 'github_id', 'star_events_count', 'fork_events_count', 'gha_license_id', 'gha_event_created_at', 'gha_created_at', 'gha_language', 'src_encoding', 'language', 'is_vendor', 'is_generated', 'length_bytes', 'extension']\n",
      "\n",
      "Contents of 'content_id' Column:\n",
      "Sample 1 content_id:\n",
      "072b3138be512a71cf4e8bbbdb657497e808d2f6\n",
      "Sample 2 content_id:\n",
      "ef273de70f3e1e28d5c95ef0b9d3dbb27c6f262c\n",
      "Sample 3 content_id:\n",
      "f5da51365d291efaf804b3889ba0b1e4c03683fa\n",
      "Sample 4 content_id:\n",
      "07543d293fdaf9ef81f673ad8f6517d57b3172aa\n",
      "Sample 5 content_id:\n",
      "4d6341e42c476e6f2d340d275b336c7fa26b5f51\n",
      "Sample 6 content_id:\n",
      "88503adcc91025aabfd06e75897b30d938014d7c\n",
      "Sample 7 content_id:\n",
      "71f7bb16f3ef4de1353242310c7164f5a94f4469\n",
      "Sample 8 content_id:\n",
      "0f45060fc1b75c91727a6139965f854388c7da32\n",
      "Sample 9 content_id:\n",
      "537a77d13dde87831afb2e3be18f9d5fa3a2d0e5\n",
      "Sample 10 content_id:\n",
      "75dfad90b7ee2f77379414eacd49a812bad75290\n",
      "\n",
      "Processed Samples:\n",
      "Sample 1: {'blob_id': 'a29dd2b33082d2b98541c66ba3620ae054991503', 'directory_id': '71568d223947f51cb007a8564e5f808e0987779e', 'path': '/src/Dapr/GameServer.Host/Dockerfile', 'content_id': '072b3138be512a71cf4e8bbbdb657497e808d2f6', 'detected_licenses': ['MIT', 'LicenseRef-scancode-unknown-license-reference'], 'license_type': 'permissive', 'repo_name': 'devblack/OpenMU', 'snapshot_id': '8cdc521178da47c9c7d2daa502dc71688835fd0a', 'revision_id': '1064b0dca1a491bc28f325e42ca6b97d406d6558', 'branch_name': 'refs/heads/master', 'visit_date': Timestamp('2023-04-07 10:56:30.043316'), 'revision_date': Timestamp('2023-03-17 20:32:25'), 'committer_date': Timestamp('2023-03-17 20:32:25'), 'github_id': None, 'star_events_count': 0, 'fork_events_count': 0, 'gha_license_id': None, 'gha_event_created_at': None, 'gha_created_at': None, 'gha_language': None, 'src_encoding': 'UTF-8', 'language': 'Dockerfile', 'is_vendor': False, 'is_generated': False, 'length_bytes': 709, 'extension': '', 'style': 'formal'}\n",
      "Sample 2: {'blob_id': '13951d8c9fe2d6d5f1fadb4fa1e7f30131eb8acc', 'directory_id': '329ff1c768d67207353a29820fe72527efe90ec6', 'path': '/srcs/grafana/Dockerfile', 'content_id': 'ef273de70f3e1e28d5c95ef0b9d3dbb27c6f262c', 'detected_licenses': [], 'license_type': 'no_license', 'repo_name': 'Hayaks/ft_services', 'snapshot_id': 'c693d1158bae211f53449c87a23ece5db469d8a4', 'revision_id': '077f031f646d73a8245f08ca8aee7343fe123c4e', 'branch_name': 'refs/heads/master', 'visit_date': Timestamp('2023-03-22 03:56:32.854595'), 'revision_date': Timestamp('2021-03-12 15:55:14'), 'committer_date': Timestamp('2021-03-12 15:55:14'), 'github_id': 284996115, 'star_events_count': 0, 'fork_events_count': 0, 'gha_license_id': None, 'gha_event_created_at': None, 'gha_created_at': None, 'gha_language': None, 'src_encoding': 'UTF-8', 'language': 'Dockerfile', 'is_vendor': False, 'is_generated': False, 'length_bytes': 491, 'extension': '', 'style': 'formal'}\n",
      "Sample 3: {'blob_id': 'ad7459a3418a720e61a609bac606f4bcba50f12d', 'directory_id': '5acf944d3986c0268f948e4795abc4959f63ac5a', 'path': '/balena-base-images/golang/asus-tinker-edge-t/debian/stretch/1.16.9/build/Dockerfile', 'content_id': 'f5da51365d291efaf804b3889ba0b1e4c03683fa', 'detected_licenses': ['Apache-2.0'], 'license_type': 'permissive', 'repo_name': 'welkin82/base-images', 'snapshot_id': '96d5b9e31f7a10d42447b065230180d35adbbee1', 'revision_id': '5ea025b2d51007ae655fb1f37c6cae63bdd32cd5', 'branch_name': 'refs/heads/master', 'visit_date': Timestamp('2023-09-02 09:24:03.678571'), 'revision_date': Timestamp('2021-11-23 14:37:09'), 'committer_date': Timestamp('2021-11-23 14:37:09'), 'github_id': None, 'star_events_count': 0, 'fork_events_count': 0, 'gha_license_id': None, 'gha_event_created_at': None, 'gha_created_at': None, 'gha_language': None, 'src_encoding': 'UTF-8', 'language': 'Dockerfile', 'is_vendor': False, 'is_generated': False, 'length_bytes': 2009, 'extension': '', 'style': 'formal'}\n",
      "Sample 4: {'blob_id': 'a1bcdb8f03400791c0a729938f9db0dd55afe59e', 'directory_id': 'a8079a2a9461cba7778a5490cff52b65d3689d3c', 'path': '/balena-base-images/node/asus-tinker-board-s/debian/buster/10.14.0/build/Dockerfile', 'content_id': '07543d293fdaf9ef81f673ad8f6517d57b3172aa', 'detected_licenses': ['Apache-2.0'], 'license_type': 'permissive', 'repo_name': 'r4space/base-images', 'snapshot_id': '4c1564a051dcef05d7756f44c97d2e5a68b2a652', 'revision_id': '75b59aa7266507ae51f8d67f7629f3c1e1e51ed8', 'branch_name': 'refs/heads/master', 'visit_date': Timestamp('2020-04-16 11:49:10.807913'), 'revision_date': Timestamp('2018-12-07 18:18:12'), 'committer_date': Timestamp('2018-12-07 18:18:12'), 'github_id': None, 'star_events_count': 0, 'fork_events_count': 0, 'gha_license_id': None, 'gha_event_created_at': None, 'gha_created_at': None, 'gha_language': None, 'src_encoding': 'UTF-8', 'language': 'Dockerfile', 'is_vendor': False, 'is_generated': False, 'length_bytes': 1627, 'extension': '', 'style': 'formal'}\n",
      "Sample 5: {'blob_id': '094d9134c017399ccda24af08e9b02c63cd63ef7', 'directory_id': '2a83a18d9c9da3b28d52e80c9b073bbe1101fb9e', 'path': '/Dockerfile', 'content_id': '4d6341e42c476e6f2d340d275b336c7fa26b5f51', 'detected_licenses': [], 'license_type': 'no_license', 'repo_name': 'multicast/docker-stretch', 'snapshot_id': 'c9cb904af817216b657eb87f51419eacfb44a45c', 'revision_id': 'c30b8af4fbff5bd2b50bf2a41a323a8cca29d895', 'branch_name': 'refs/heads/master', 'visit_date': Timestamp('2020-05-15 13:05:48.405871'), 'revision_date': Timestamp('2020-02-09 01:41:21'), 'committer_date': Timestamp('2020-02-09 01:41:21'), 'github_id': 182288741, 'star_events_count': 0, 'fork_events_count': 0, 'gha_license_id': None, 'gha_event_created_at': None, 'gha_created_at': None, 'gha_language': None, 'src_encoding': 'UTF-8', 'language': 'Dockerfile', 'is_vendor': False, 'is_generated': False, 'length_bytes': 323, 'extension': '', 'style': 'formal'}\n",
      "Sample 6: {'blob_id': '8530d100937ca66ab6fee60df5127d7b8a577c81', 'directory_id': 'feae6bd3a236b507ac7d5500633ac020ba17e548', 'path': '/Dockerfile', 'content_id': '88503adcc91025aabfd06e75897b30d938014d7c', 'detected_licenses': [], 'license_type': 'no_license', 'repo_name': 'Valgueiro/cym-compiler', 'snapshot_id': 'c986ddabb3611de35840b4d4e4d42e5d9aa71fba', 'revision_id': 'b1d81c7e620c5337784730694330cab68036a565', 'branch_name': 'refs/heads/master', 'visit_date': Timestamp('2020-05-22 01:59:23.378398'), 'revision_date': Timestamp('2019-06-16 23:35:27'), 'committer_date': Timestamp('2019-06-16 23:35:27'), 'github_id': 186189364, 'star_events_count': 0, 'fork_events_count': 0, 'gha_license_id': None, 'gha_event_created_at': Timestamp('2019-06-15 22:10:36'), 'gha_created_at': Timestamp('2019-05-11 23:03:30'), 'gha_language': 'Python', 'src_encoding': 'UTF-8', 'language': 'Dockerfile', 'is_vendor': False, 'is_generated': False, 'length_bytes': 713, 'extension': '', 'style': 'formal'}\n",
      "Sample 7: {'blob_id': '1038d2fe525b47d8095a243469563afd96b9f1f4', 'directory_id': '1da39b782291e8d591d2bc1c615da33a54915a36', 'path': '/Dockerfile', 'content_id': '71f7bb16f3ef4de1353242310c7164f5a94f4469', 'detected_licenses': [], 'license_type': 'no_license', 'repo_name': 'ernestoagc/form-api', 'snapshot_id': 'd2544f1efa5ae1e1863114556b861084894b241b', 'revision_id': 'dac3f1a352957d6618435595cf65e63c74821939', 'branch_name': 'refs/heads/main', 'visit_date': Timestamp('2023-04-17 20:42:48.395168'), 'revision_date': Timestamp('2021-04-29 21:39:49'), 'committer_date': Timestamp('2021-04-29 21:39:49'), 'github_id': 343963045, 'star_events_count': 0, 'fork_events_count': 0, 'gha_license_id': None, 'gha_event_created_at': None, 'gha_created_at': None, 'gha_language': None, 'src_encoding': 'UTF-8', 'language': 'Dockerfile', 'is_vendor': False, 'is_generated': False, 'length_bytes': 374, 'extension': '', 'style': 'formal'}\n",
      "Sample 8: {'blob_id': '29684f92174f2ea806f2e83a9a507101223e2526', 'directory_id': 'e833cea0e412af76dd5d239314b927c21dd4ae5c', 'path': '/data/a/analogic/mbase/Dockerfile', 'content_id': '0f45060fc1b75c91727a6139965f854388c7da32', 'detected_licenses': ['MIT'], 'license_type': 'permissive', 'repo_name': 'jsdelivrbot/dockerfiles-1', 'snapshot_id': 'f12701ea282f8542b8cbbdbb38b15e40e56a5788', 'revision_id': 'cb65d635e75305fe1034ea452e23d49f9134faab', 'branch_name': 'refs/heads/master', 'visit_date': Timestamp('2020-04-10 08:57:54.023588'), 'revision_date': Timestamp('2018-12-08 05:37:38'), 'committer_date': Timestamp('2018-12-08 05:37:38'), 'github_id': 160921155, 'star_events_count': 0, 'fork_events_count': 0, 'gha_license_id': 'MIT', 'gha_event_created_at': Timestamp('2018-12-08 08:51:17'), 'gha_created_at': Timestamp('2018-12-08 08:51:17'), 'gha_language': None, 'src_encoding': 'UTF-8', 'language': 'Dockerfile', 'is_vendor': False, 'is_generated': False, 'length_bytes': 2086, 'extension': '', 'style': 'formal'}\n",
      "Sample 9: {'blob_id': '4e2625061d8aa48a2f794c30b7a26060ba46362a', 'directory_id': 'e833cea0e412af76dd5d239314b927c21dd4ae5c', 'path': '/data/d/diameter/rtorrent-rutorrent/Dockerfile', 'content_id': '537a77d13dde87831afb2e3be18f9d5fa3a2d0e5', 'detected_licenses': ['MIT'], 'license_type': 'permissive', 'repo_name': 'jsdelivrbot/dockerfiles-1', 'snapshot_id': 'f12701ea282f8542b8cbbdbb38b15e40e56a5788', 'revision_id': 'cb65d635e75305fe1034ea452e23d49f9134faab', 'branch_name': 'refs/heads/master', 'visit_date': Timestamp('2020-04-10 08:57:54.023588'), 'revision_date': Timestamp('2018-12-08 05:37:38'), 'committer_date': Timestamp('2018-12-08 05:37:38'), 'github_id': 160921155, 'star_events_count': 0, 'fork_events_count': 0, 'gha_license_id': 'MIT', 'gha_event_created_at': Timestamp('2018-12-08 08:51:17'), 'gha_created_at': Timestamp('2018-12-08 08:51:17'), 'gha_language': None, 'src_encoding': 'UTF-8', 'language': 'Dockerfile', 'is_vendor': False, 'is_generated': False, 'length_bytes': 1093, 'extension': '', 'style': 'formal'}\n",
      "Sample 10: {'blob_id': '4ab921911e4ccbc6bbbade74b2e7cf50108828d6', 'directory_id': '38896951aea62f5b87fcb236c149647513f1889c', 'path': '/.dev/docker/doc/Dockerfile', 'content_id': '75dfad90b7ee2f77379414eacd49a812bad75290', 'detected_licenses': ['BSD-3-Clause'], 'license_type': 'permissive', 'repo_name': 'PointCloudLibrary/pcl', 'snapshot_id': '243714ed366a277f60a8097e133e195f3b91321c', 'revision_id': 'f2492bd65cb1e9c48a60f5e27296e25e1835169a', 'branch_name': 'refs/heads/master', 'visit_date': Timestamp('2023-09-04 17:55:05.319149'), 'revision_date': Timestamp('2023-09-04 07:40:09'), 'committer_date': Timestamp('2023-09-04 07:40:09'), 'github_id': 8162615, 'star_events_count': 9065, 'fork_events_count': 4836, 'gha_license_id': 'NOASSERTION', 'gha_event_created_at': Timestamp('2023-09-14 19:47:04'), 'gha_created_at': Timestamp('2013-02-12 16:40:25'), 'gha_language': 'C++', 'src_encoding': 'UTF-8', 'language': 'Dockerfile', 'is_vendor': False, 'is_generated': False, 'length_bytes': 335, 'extension': '', 'style': 'formal'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Login using your Hugging Face token\n",
    "login(token=\"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\")\n",
    "\n",
    "# Step 1: Load the Dockerfile dataset\n",
    "ds_dockerfile = load_dataset(\"bigcode/the-stack-v2\", \"Dockerfile\", split=\"train\")\n",
    "\n",
    "# Display column namesG\n",
    "print(\"Dataset Columns:\", ds_dockerfile.column_names)\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Preprocessing - cleaning and tokenizing\n",
    "def preprocess_code(sample):\n",
    "    # Ensure 'content_id' key exists\n",
    "    content_id = sample.get('content_id', '')  # Default to empty string if 'content_id' doesn't exist\n",
    "    if not content_id:\n",
    "        print(\"Skipping sample due to missing 'content_id':\", sample)  # Debugging log\n",
    "        return sample  # Return the sample without modification if 'content_id' is missing\n",
    "\n",
    "    # Clean the content_id (remove comments, extra whitespace, etc.)\n",
    "    content_id = re.sub(r'#.*', '', content_id)  # Remove comments\n",
    "    content_id = re.sub(r'\\s+', ' ', content_id)  # Remove extra whitespace\n",
    "    content_id = content_id.strip()\n",
    "    \n",
    "    # Tokenize the content_id (you can use a more advanced tokenizer if required)\n",
    "    tokens = content_id.split()  # Basic tokenization\n",
    "    sample['content_id'] = ' '.join(tokens)  # Update the content_id in the sample\n",
    "    \n",
    "    return sample\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "ds_dockerfile = ds_dockerfile.map(preprocess_code)\n",
    "\n",
    "# Step 3: Augmenting the dataset with response style/tone tags\n",
    "def augment_with_tags(sample):\n",
    "    # Add a static or dynamic style tag\n",
    "    sample['style'] = 'formal'  # Example: static tag\n",
    "    return sample\n",
    "\n",
    "# Apply augmentation\n",
    "ds_dockerfile = ds_dockerfile.map(augment_with_tags)\n",
    "\n",
    "print(\"\\nContents of 'content_id' Column:\")\n",
    "for i, sample in enumerate(ds_dockerfile):\n",
    "    print(f\"Sample {i + 1} content_id:\\n{sample['content_id']}\")\n",
    "    if i == 9:  # Stop after 10 samples\n",
    "        break\n",
    "\n",
    "# Step 4: Iterate through 10 samples and display the results\n",
    "print(\"\\nProcessed Samples:\")\n",
    "for i, sample in enumerate(ds_dockerfile):\n",
    "    print(f\"Sample {i + 1}: {sample}\")\n",
    "    if i == 9:  # Stop after 10 iterations\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "159a745d-95f0-4835-8772-c90c6e81f96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/daniel/anaconda3/lib/python3.12/site-packages (4.47.1)\n",
      "Requirement already satisfied: filelock in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/daniel/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/daniel/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/daniel/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/daniel/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniel/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a0546de-9707-4b6d-8f12-3b39d5fdde64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/daniel/anaconda3/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in /home/daniel/anaconda3/lib/python3.12/site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in /home/daniel/anaconda3/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/daniel/anaconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb6250bf-38d9-4fe1-b442-cd72de31d308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /home/daniel/anaconda3/lib/python3.12/site-packages (4.47.1)\n",
      "Requirement already satisfied: filelock in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers[torch]) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers[torch]) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers[torch]) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers[torch]) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers[torch]) (4.66.5)\n",
      "Requirement already satisfied: torch in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers[torch]) (2.5.1)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from transformers[torch]) (1.2.1)\n",
      "Requirement already satisfied: psutil in /home/daniel/anaconda3/lib/python3.12/site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/daniel/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (4.11.0)\n",
      "Requirement already satisfied: networkx in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch->transformers[torch]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch->transformers[torch]) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch->transformers[torch]) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch->transformers[torch]) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch->transformers[torch]) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch->transformers[torch]) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch->transformers[torch]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch->transformers[torch]) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch->transformers[torch]) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/daniel/anaconda3/lib/python3.12/site-packages (from torch->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/daniel/anaconda3/lib/python3.12/site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/daniel/anaconda3/lib/python3.12/site-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/daniel/anaconda3/lib/python3.12/site-packages (from requests->transformers[torch]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniel/anaconda3/lib/python3.12/site-packages (from requests->transformers[torch]) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f2f21b0-4708-49fd-abac-a43cb0ece63d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds_dockerfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 113\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenized\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Apply tokenization and remove unnecessary columns\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m tokenized_dockerfile \u001b[38;5;241m=\u001b[39m ds_dockerfile\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m    114\u001b[0m     tokenize_function,\n\u001b[1;32m    115\u001b[0m     batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    116\u001b[0m     remove_columns\u001b[38;5;241m=\u001b[39mds_dockerfile\u001b[38;5;241m.\u001b[39mcolumn_names,  \u001b[38;5;66;03m# Remove irrelevant columns\u001b[39;00m\n\u001b[1;32m    117\u001b[0m )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Set training arguments\u001b[39;00m\n\u001b[1;32m    120\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m    121\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    122\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m     remove_unused_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# Allow custom columns\u001b[39;00m\n\u001b[1;32m    134\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds_dockerfile' is not defined"
     ]
    }
   ],
   "source": [
    "# from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "\n",
    "# # Load pre-trained GPT-2 model and tokenizer\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# # Add a padding token (if not already set)\n",
    "# if tokenizer.pad_token is None:\n",
    "#     tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# # Tokenize the dataset\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples['content_id'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# # Apply tokenization to the dataset\n",
    "# tokenized_dockerfile = ds_dockerfile.map(tokenize_function, batched=True)\n",
    "\n",
    "# # Set training arguments\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./results\",          # output directory\n",
    "#     num_train_epochs=3,              # number of training epochs\n",
    "#     per_device_train_batch_size=4,   # batch size for training\n",
    "#     per_device_eval_batch_size=8,    # batch size for evaluation\n",
    "#     warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "#     weight_decay=0.01,               # strength of weight decay\n",
    "#     logging_dir=\"./logs\",            # directory for storing logs\n",
    "#     logging_steps=10,\n",
    "# )\n",
    "\n",
    "# # Initialize the Trainer\n",
    "# trainer = Trainer(\n",
    "#     model=model,                         # the pre-trained model\n",
    "#     args=training_args,                  # training arguments\n",
    "#     train_dataset=tokenized_dockerfile,   # training dataset\n",
    "#     eval_dataset=tokenized_dockerfile     # evaluation dataset\n",
    "# )\n",
    "\n",
    "# # Fine-tune the model\n",
    "# trainer.train()\n",
    "\n",
    "# # optimizing performance\n",
    "# from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "\n",
    "# # Load pre-trained GPT-2 model and tokenizer\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# # Add a padding token (if not already set)\n",
    "# if tokenizer.pad_token is None:\n",
    "#     tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# # Tokenize the dataset efficiently\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples['content_id'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# # Apply tokenization with `with_transform` to avoid dataset copies\n",
    "# ds_dockerfile = ds_dockerfile.with_transform(tokenize_function)\n",
    "\n",
    "# # Set optimized training arguments\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./results\",          # output directory\n",
    "#     num_train_epochs=3,              # number of training epochs\n",
    "#     per_device_train_batch_size=8,   # increase batch size for efficiency\n",
    "#     per_device_eval_batch_size=16,   # larger eval batch size\n",
    "#     warmup_steps=500,                # warmup steps for scheduler\n",
    "#     weight_decay=0.01,               # weight decay\n",
    "#     logging_dir=\"./logs\",            # logs directory\n",
    "#     logging_steps=100,               # reduce logging frequency\n",
    "#     fp16=True,                       # enable mixed precision\n",
    "#     gradient_accumulation_steps=2,   # accumulate gradients to reduce memory\n",
    "#     save_total_limit=2,              # limit saved checkpoints\n",
    "#     dataloader_num_workers=4,        # use multiple workers for data loading\n",
    "#     disable_tqdm=True,               # disable tqdm for less CPU overhead\n",
    "# )\n",
    "\n",
    "# # Initialize the Trainer\n",
    "# trainer = Trainer(\n",
    "#     model=model,                         # the pre-trained model\n",
    "#     args=training_args,                  # training arguments\n",
    "#     train_dataset=ds_dockerfile,         # training dataset\n",
    "#     eval_dataset=ds_dockerfile           # evaluation dataset\n",
    "# )\n",
    "\n",
    "# # Fine-tune the model\n",
    "# trainer.train()\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Add a padding token (if not already set)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"content_id\"],  # Adjust this to the correct column for text data\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,  # Adjust max length as needed\n",
    "    )\n",
    "    # Set labels equal to input_ids for language modeling\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n",
    "\n",
    "# Apply tokenization and remove unnecessary columns\n",
    "tokenized_dockerfile = ds_dockerfile.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=ds_dockerfile.column_names,  # Remove irrelevant columns\n",
    ")\n",
    "\n",
    "# Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=2,\n",
    "    save_total_limit=2,\n",
    "    dataloader_num_workers=4,\n",
    "    remove_unused_columns=False,  # Allow custom columns\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dockerfile,\n",
    "    eval_dataset=tokenized_dockerfile,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959017d8-1b00-411c-89d3-1a1a082eb859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./fine_tuned_model\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edc36f2-db42-4952-9bbf-77ea0f9612af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae3b2a5-dc18-48e4-bb05-5fffc643dd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccc7c25-d383-4da3-952a-cd4cebe71e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
